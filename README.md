# Appleâ€‘OSÂ Onâ€‘DeviceÂ Benchmarking

A tiny SwiftUI app for stressâ€‘testing Appleâ€™s onâ€‘device **LanguageModelSession** (LLM) APIs.  It runs a bank of reasoningâ€¯+â€¯generative prompts multiple times, logs latency/throughput metrics, and exports full CSVsâ€”perfect for quick performance pokes at iPhone/iPad hardware.

---

## âœ¨ Features

* Warm-start benchmarking mode with configurable trial count (cold-start still a WIP)
* Automatic retry of failed prompts with error logging
* MeanÂ Â±Â SD bar charts for **Latency**, **Tokens**, **TTFT**, and **TPS**
* Oneâ€‘click CSV export of *all* trial dataÂ + separate failure log

---

## ğŸ”§ Requirements

| Tool / OS             | Minimum Version | Notes                                                 |
| --------------------- | --------------- | ----------------------------------------------------- |
| **macOS**             | 14.0Â (Sonoma)   |                             |
| **Xcode**             | 16Â Î² or later   | Must include the *iOSÂ 26* & *macOSÂ 15* SDKs           |
| **iOSÂ device**        | iOSÂ 26Â Î²        | iPhone/iPad with an A17/Mâ€‘class chip for best results |
| **Developer account** | Free or paid    | Needed to sign & run on physical devices              |

> **Headsâ€‘up:** The app uses the new `FoundationModels` framework (`LanguageModelSession`).  That SDK ships only with XcodeÂ 16+.

---

## ğŸš€ QuickÂ Start

```bash
# 1. Clone
$ git clone https://github.com/singhh5050/apple-os-on-device-benchmarking.git
$ cd apple-os-on-device-benchmarking

# 2. Open the Xcode project
$ open apple-os-on-device-benchmarking.xcodeproj
```

### Deploy to iPhone (iOSÂ 26)

1. **Plug in** (or pair wirelessly) an iOSÂ 26 device.
2. Allow the *â€œTrust This Computerâ€* prompt and enable **DeveloperÂ Mode** on the phone (Settings â–¸ Privacy &Â Security â–¸ Developer Mode).
3. In Xcode, choose your device from the runâ€‘target dropâ€‘down.
4. Xcode will prompt for a signing teamâ€”pick your AppleÂ ID (or any team).
5. Press **â–¶ï¸ Run**.  The app installs and launches onâ€‘device.
6. Tap **Run Benchmarks**. (and select your desired settings) There's a link to export to *benchmark\_results.csv* when done.

---

## ğŸ“‚ Project Layout

```
apple-os-on-device-benchmarking
â”œâ”€â”€ Assets.xcassets/          # App icon + accent colour
â”œâ”€â”€ apple_os_on_device_benchmarkingApp.swift  # main SwiftUI file (all logic/UI)
â””â”€â”€ apple-os-on-device-benchmarking.xcodeproj/ # Xcode project
```

---

## ğŸ—œï¸ CSVÂ Columns

| Column       | Meaning                       |
| ------------ | ----------------------------- |
| `prompt`     | Full prompt text              |
| `difficulty` | easy / medium / hard          |
| `type`       | reasoning / generative        |
| `tokens`     | Tokens generated              |
| `ttftMs`     | Timeâ€‘toâ€‘firstâ€‘token (ms)      |
| `latencyMs`  | Total generation latency (ms) |
| `tps`        | Tokens per second             |

Failures are logged separately with `prompt`, `difficulty`, and the error message.

---

## ğŸ›¡ï¸ License

MIT Â©Â 2025Â HarshÂ Singh
